{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1k-Gas_aECIt3P2tchfIxB797LmueU0q2",
      "authorship_tag": "ABX9TyPijJTwUiYvljUeyS2dEmTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/that1guy15/ai_notebooks/blob/main/YOLOv8_ASL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLocbPcAT7JH"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics datasets huggingface_hub opencv-python vidgear[core]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from datetime import datetime\n",
        "\n",
        "# Check if a GPU is available and set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "WzFRxUE4hC1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "4eMNM0wLY-mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!ln -s /content/drive/My\\ Drive/AI/datasets/sign_language /content/datasets\n",
        "\n",
        "DS_PATH = \"/content/datasets\"\n"
      ],
      "metadata": {
        "id": "_yjgROr2wzKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select a Training Dataset\n",
        "\n",
        "other datasets for notes:\n",
        "\n",
        "### Alphabet\n",
        "asl_alphabet:\n",
        "  https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
        "\n",
        "### Words\n",
        "sign_recognition.v2i.yolov8:\n",
        "  https://universe.roboflow.com/ss-hwnzd/sign_recognition/dataset/2\n",
        "\n",
        "\n",
        "### Mixed\n",
        "asllrp:\n",
        "  http://dai.cs.rutgers.edu/dai/s/index;jsessionid=B88576310F7A2C5EBCF75E98A2C5CB92?redirect=wlasl\n"
      ],
      "metadata": {
        "id": "K2O1QHSl0_Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ASL Datasets:\n",
        "ASL_seg = f\"{DS_PATH}/ASL-SEG.v2i.coco-segmentation\"                      #https://universe.roboflow.com/manu-fd9da/asl-seg/dataset/2\n",
        "ASL_detect = f\"{DS_PATH}/ASL-Detection.v1i.yolov8\"                        #https://universe.roboflow.com/manu-fd9da/asl-seg/dataset/2\n",
        "ASL_alphabet = f\"{DS_PATH}/american_sign_language_letters.v1-v1.yolov8\"   #https://public.roboflow.com/object-detection/american-sign-language-letters"
      ],
      "metadata": {
        "id": "rafklyWFcVda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "yWhTaNRy1KFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Model\n",
        "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
        "model = YOLO(\"yolov8n-seg.pt\")  # load a pretrained segmentation model\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.train(data=f\"{roboflow}/data.yaml\",\n",
        "            project=f\"{roboflow}/training_jobs/result_dir\",\n",
        "            name=f\"roboflow_trained_100_epochs_{datetime.utcnow():%Y%m%d_%H%M%S}\",\n",
        "            batch = 80,\n",
        "            epochs=100)\n",
        "\n",
        "# Evaluate model performance on the validation set\n",
        "results = model.val()"
      ],
      "metadata": {
        "id": "7yz2NEOupyVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict with Your New Model"
      ],
      "metadata": {
        "id": "Qi8ijuTr1P49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "asl_model = YOLO(\"/content/datasets/sign_recognition.v2i.yolov8try_again/result_dir/roboflow_trained_100_epochs_20240217_164244/weights/best.pt\")\n",
        "\n",
        "test_dir = '/content/datasets/sign_recognition.v2i.yolov8/valid/images'\n",
        "test_image = '/W-7-_jpg.rf.1eb713c5c14ed8c1434a5ead73b44290.jpg'\n",
        "\n",
        "res0 = asl_model.predict(f\"{test_dir}/{test_image}\", conf = 0.6)[0]\n",
        "\n",
        "new_result_array = res0.plot()\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(new_result_array)"
      ],
      "metadata": {
        "id": "iKS5_fu4n2Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from pprint import pprint\n",
        "\n",
        "def find_files(directory, extension):\n",
        "    if not extension.startswith('.'):\n",
        "        extension = f\".{extension}\"\n",
        "\n",
        "    pattern = os.path.join(directory, '*' + extension)\n",
        "    return glob.glob(pattern)\n"
      ],
      "metadata": {
        "id": "tG7XK2eDn2Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run batched inference on a list of images\n",
        "results = asl_model(test_dir, stream=True)                        # return a generator of Results objects from given directory\n",
        "#results = asl_model(find_files(test_dir, '.jpg'), stream=True)    # return a generator of Results objects from list of files\n",
        "\n",
        "# Process results generator\n",
        "for result in results:\n",
        "    boxes = result.boxes                # Boxes object for bounding box outputs\n",
        "    masks = result.masks                # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints        # Keypoints object for pose outputs\n",
        "    probs = result.probs                # Probs object for classification outputs\n",
        "    result.show()                       # display to screen\n",
        "    #result.save(filename='result.jpg')  # save to disk\n",
        "\n",
        "    new_result_array = result.plot()\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(new_result_array)"
      ],
      "metadata": {
        "id": "-MddFfNdn2Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting from a Streaming Loop or Video"
      ],
      "metadata": {
        "id": "NDae4IZS9bSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def cv2_imshow(a, **kwargs):\n",
        "    a = a.clip(0, 255).astype('uint8')\n",
        "    # cv2 stores colors as BGR; convert to RGB\n",
        "    if a.ndim == 3:\n",
        "        if a.shape[2] == 4:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "        else:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return plt.imshow(a, **kwargs)"
      ],
      "metadata": {
        "id": "LgQr9xIkGr8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from vidgear.gears import CamGear\n",
        "\n",
        "stream = CamGear(\n",
        "    source=\"https://www.youtube.com/watch?v=tkMg8g8vVUo\",\n",
        "    stream_mode=True,\n",
        "    logging=True\n",
        "    ).start()\n",
        "\n",
        "\n",
        "while True:\n",
        "  # read frames\n",
        "  frame = stream.read()\n",
        "\n",
        "  # check if frame is None\n",
        "  if frame is None:\n",
        "      #if True break the infinite loop\n",
        "      break\n",
        "\n",
        "  results = asl_model(frame)\n",
        "  annotated_frame = results[0].plot()\n",
        "\n",
        "  cv2.imshow(\"YOLOv8 Prediction\", annotated_frame)\n",
        "  # Show output window\n",
        "\n",
        "  key = cv2.waitKey(1) & 0xFF\n",
        "  # check for 'q' key-press\n",
        "  if key == ord(\"q\"):\n",
        "      #if 'q' key-pressed break out\n",
        "      break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "# close output window\n",
        "\n",
        "# safely close video stream.\n",
        "stream.stop()"
      ],
      "metadata": {
        "id": "PK-5RlgSn2B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sF2RQnoPn1_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xhwrg9Xtn18z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l74VFzPDn16L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjsOVW2nn11o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXjkshgyn1s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R0mtr7ZRn1jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uEhXjJncn1Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZ3EPMZxn1Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_ext tensorboard\n",
        "tensorboard --logdir ultralytics/runs  # replace with 'runs' directory"
      ],
      "metadata": {
        "id": "mbDiAjz0ns3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image"
      ],
      "metadata": {
        "id": "xuLFEV64fKP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "gwhbOgDLl2nA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}